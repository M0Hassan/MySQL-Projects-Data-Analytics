# Layoffs Data Analysis Repository

## Overview

This repository contains two key projects related to analyzing layoffs data from 2022, sourced from Kaggle:

- **Data Cleaning:** This project focuses on preparing the layoffs dataset for analysis by ensuring data quality through cleaning processes like handling duplicates, standardizing data, and managing null values.

- **Exploratory Data Analysis (EDA):** Following the data cleaning phase, this project delves into exploring the dataset to uncover trends, patterns, and outliers. It includes analyses across various dimensions like time, location, industry, and company specifics.

## Project Structure

- **data_cleaning/**
  - Contains scripts and documentation for cleaning the raw layoffs data.
  - **README.md:** Detailed explanation of the data cleaning steps.

- **eda/**
  - Houses the EDA scripts, data visualizations, and analysis results.
  - **README.md:** Step-by-step description of the EDA process.

## Content Summary

- **Data Cleaning:** 
  - The focus is on data preprocessing, ensuring the dataset is ready for analysis. This includes:
    - Removal of duplicate entries.
    - Standardization of format and values across different columns.
    - Handling of missing data to maintain dataset integrity.

- **Exploratory Data Analysis:**
  - Here, we explore the cleaned data to understand:
    - The scale and impact of layoffs across different sectors.
    - Temporal patterns which might indicate economic or industry-specific trends.
    - Geographical distribution to highlight regions with significant layoffs.
    - Identification of outliers, like companies that completely laid off their workforce.

## Usage

Each sub-directory (`data_cleaning` and `eda`) has its own README file with detailed SQL queries and analysis steps. Users interested in the specifics of data cleaning or EDA can refer to these files for comprehensive insights and code examples.


---
